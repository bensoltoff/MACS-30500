---
title: "Text analysis: fundamentals and sentiment analysis"
author: "INFO 5940 <br /> Cornell University"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      highlightStyle: magula
      highlightLines: true
      highlightLanguage: r
      ratio: 16:9
      countIncrementalSlides: false
---

```{r}
#| label = "setup",
#| include = FALSE
# generate CSS file
library(xaringanthemer)
style_duo_accent(
  primary_color = "#B31B1B",
  secondary_color = "#F8981D",
  inverse_header_color = "#222222",
  black_color = "#222222",
  header_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  text_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  code_font_google = xaringanthemer::google_font("Source Code Pro"),
  base_font_size = "24px",
  code_font_size = "20px",
  # title_slide_background_image = "https://github.com/uc-dataviz/course-notes/raw/main/images/hexsticker.svg",
  # title_slide_background_size = "contain",
  # title_slide_background_position = "top",
  header_h1_font_size = "2rem",
  header_h2_font_size = "1.75rem",
  header_h3_font_size = "1.5rem",
  extra_css = list(
    "h1" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h2" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h3" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    ".tiny" = list("font-size" = "70%"),
    ".small" = list("font-size" = "90%"),
    ".midi" = list("font-size" = "150%"),
    ".tiny .remark-code" = list("font-size" = "70%"),
    ".small .remark-code" = list("font-size" = "90%"),
    ".midi .remark-code" = list("font-size" = "150%"),
    ".large" = list("font-size" = "200%"),
    ".xlarge" = list("font-size" = "600%"),
    ".huge" = list(
      "font-size" = "400%",
      "font-family" = "'Montserrat', sans-serif",
      "font-weight" = "bold"
    ),
    ".hand" = list(
      "font-family" = "'Gochi Hand', cursive",
      "font-size" = "125%"
    ),
    ".task" = list(
      "padding-right" = "10px",
      "padding-left" = "10px",
      "padding-top" = "3px",
      "padding-bottom" = "3px",
      "margin-bottom" = "6px",
      "margin-top" = "6px",
      "border-left" = "solid 5px #F1DE67",
      "background-color" = "#F3D03E"
    ),
    ".pull-left" = list(
      "width" = "49%",
      "float" = "left"
    ),
    ".pull-right" = list(
      "width" = "49%",
      "float" = "right"
    ),
    ".pull-left-wide" = list(
      "width" = "70%",
      "float" = "left"
    ),
    ".pull-right-narrow" = list(
      "width" = "27%",
      "float" = "right"
    ),
    ".pull-left-narrow" = list(
      "width" = "27%",
      "float" = "left"
    ),
    ".pull-right-wide" = list(
      "width" = "70%",
      "float" = "right"
    ),
    ".blue" = list(color = "#2A9BB7"),
    ".purple" = list(color = "#a493ba"),
    ".yellow" = list(color = "#f1de67"),
    ".gray" = list(color = "#222222")
  )
)

source(here::here("R", "slide-opts.R"))
xaringanExtra::use_panelset()
```

```{r}
#| label = "pkgs",
#| include = FALSE,
#| cache = FALSE
options(htmltools.dir.version = FALSE)

library(tidyverse)
library(tidytext)
library(scales)
library(here)
library(patchwork)
library(magrittr)
library(countdown)

set.seed(1234)
theme_set(theme_minimal(base_size = 16))
```

# Basic workflow for text analysis

* Obtain your text sources
* Extract documents and move into a corpus
* Transformation
* Extract features
* Perform analysis

---

# Obtain your text sources

* Web sites
    * Twitter
* Databases
* PDF documents
* Digital scans of printed materials

---

# Extract documents and move into a corpus

* Text corpus
* Typically stores the text as a raw character string with metadata and details stored with the text

---

# Transformation

* Tag segments of speech for part-of-speech (nouns, verbs, adjectives, etc.) or entity recognition (person, place, company, etc.)
* Standard text processing
    * Convert to lower case
    * Remove punctuation
    * Remove numbers
    * Remove stopwords
    * Remove domain-specific stopwords
    * Stemming

---

# Extract features

* Convert the text string into some sort of quantifiable measures
* Bag-of-words model
    * Term frequency vector
    * Term-document matrix
    * Ignores context
* Word embeddings

---

# Word embeddings

```{r}
#| echo = FALSE
include_graphics(path = "https://blogs.mathworks.com/images/loren/2017/vecs.png")
```

---

# Perform analysis

* Basic
    * Word frequency
    * Collocation
    * Dictionary tagging
* Advanced
    * Document classification
    * Corpora comparison
    * Topic modeling

---

# [`tidytext`](https://github.com/juliasilge/tidytext)

* Tidy text format
* Defined as one-term-per-row
* Differs from the term-document matrix
    * One-document-per-row and one-term-per-column

---

# Get text corpa

```{r}
#| label = "janeausten-corpa",
#| echo = FALSE
library(janeaustenr)

(books <- austen_books() %>%
    group_by(book) %>%
    mutate(linenumber = row_number(),
           chapter = cumsum(str_detect(text,
                                       regex("^chapter [\\divxlc]",
                                             ignore_case = TRUE)))) %>%
    ungroup())
```

---

# Tokenize text

```{r}
#| label = "janeausten-token",
#| dependson = "janeausten-corpa"
(tidy_books <- books %>%
   unnest_tokens(output = word, input = text))
```

---

# Practice using `tidytext`

> How often is each U.S. state mentioned in a popular song?

* Billboard Year-End Hot 100 (1958-present)
* Census Bureau ACS

---

# Song lyrics

* [Reference](https://youtu.be/OPf0YbXqDm0?t=91)

```{r}
#| label = "lyrics-import",
#| include = FALSE
song_lyrics <- here("static", "data", "billboard_lyrics_1964-2015.csv") %>%
  read_csv()
```

```{r}
#| label = "lyrics-example",
#| dependson = "lyrics-import",
#| echo = FALSE
song_lyrics %>%
  filter(Song == "uptown funk") %$%
  Lyrics %>%
  str_wrap() %>%
  cat()
```

---

<div style="width:100%;height:0;padding-bottom:56%;position:relative;"><iframe src="https://giphy.com/embed/2aJM3TUEaY9Yz166e8" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>

```{r}
#| echo = FALSE,
#| cache = FALSE
countdown(minutes = 10)
```

---

# Sentiment analysis

> I am happy

---

# Dictionaries

```{r}
#| label = "bing"
get_sentiments("bing")
```

---

# Dictionaries

```{r}
#| label = "afinn"
get_sentiments("afinn")
```

---

# `janeaustenr`

.pull-left[

##### Sense and Sensibility

```{r}
#| echo = FALSE
include_graphics(path = "https://www.quotemaster.org/images/ff/ff37422dc1a2c38dfa293ed3a0d65aa7.gif")
include_graphics(path = "https://smartbitchestrashybooks.com/WP/wp-content/uploads/2016/07/Hugh-Grant-waving-to-Emma-Thompson.gif")
```

]

.pull-right[

##### Pride and Prejudice

```{r}
#| echo = FALSE
include_graphics(path = "https://media.giphy.com/media/26FL4zFEQlJ2ffxXW/giphy.gif")
include_graphics(path = "https://media.giphy.com/media/l4JyVmADBclbnDieY/giphy.gif")
```

]

---

<div style="width:100%;height:0;padding-bottom:56%;position:relative;"><iframe src="https://giphy.com/embed/2wXrSikk2c8llaunlr" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>

---

# Calculate sentiment

```{r}
#| label = "janeausten-sentiment",
#| dependson = c("janeausten-corpa", "janeausten-token"),
#| echo = FALSE
janeaustensentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

# plot the sentiment over time in each book
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +
        geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
        facet_wrap( ~ book, ncol = 2, scales = "free_x")
```

---

# Load Harry Potter text

```{r}
#| label = "hp",
#| echo = FALSE
library(harrypotter)

# names of each book
hp_books <- c("philosophers_stone", "chamber_of_secrets",
              "prisoner_of_azkaban", "goblet_of_fire",
              "order_of_the_phoenix", "half_blood_prince",
              "deathly_hallows")

# combine books into a list
hp_words <- list(
  philosophers_stone,
  chamber_of_secrets,
  prisoner_of_azkaban,
  goblet_of_fire,
  order_of_the_phoenix,
  half_blood_prince,
  deathly_hallows
) %>%
  # name each list element
  set_names(hp_books) %>%
  # convert each book to a data frame and merge into a single data frame
  map_df(as_tibble, .id = "book") %>%
  # convert book to a factor
  mutate(book = factor(book, levels = hp_books)) %>%
  # remove empty chapters
  drop_na(value) %>%
  # create a chapter id column
  group_by(book) %>%
  mutate(chapter = row_number(book)) %>%
  # tokenize the data frame
  unnest_tokens(word, value)

hp_words
```

---

# Most frequent words, by book

```{r}
#| label = "word-freq",
#| echo = FALSE
hp_words %>%
  # delete stopwords
  anti_join(stop_words) %>%
  # summarize count per word per book
  count(book, word, sort = TRUE) %>%
  # get top 15 words per book
  group_by(book) %>%
  top_n(15) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, n, book)) %>%
  # create barplot
  ggplot(aes(x = word, y = n, fill = book)) + 
  geom_col(color = "black") +
  scale_x_reordered() +
  labs(title = "Most frequent words in Harry Potter",
       x = NULL,
       y = "Word count") +
  facet_wrap(~ book, scales = "free", nrow = 2) +
  coord_flip() +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none")
```

---

# Exercises

<div style="width:100%;height:0;padding-bottom:59%;position:relative;"><iframe src="https://giphy.com/embed/pI2paNxecnUNW" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>

```{r}
#| echo = FALSE,
#| cache = FALSE
countdown(minutes = 10)
```
