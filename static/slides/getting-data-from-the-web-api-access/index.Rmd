---
title: "Getting data from the web: API access"
author: "INFO 5940 <br /> Cornell University"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      highlightStyle: magula
      highlightLines: true
      highlightLanguage: r
      ratio: 16:9
      countIncrementalSlides: false
---

```{r}
#| label = "setup",
#| include = FALSE
# generate CSS file
library(xaringanthemer)
style_duo_accent(
  primary_color = "#B31B1B",
  secondary_color = "#F8981D",
  inverse_header_color = "#222222",
  black_color = "#222222",
  header_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  text_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  code_font_google = xaringanthemer::google_font("Source Code Pro"),
  base_font_size = "24px",
  code_font_size = "20px",
  # title_slide_background_image = "https://github.com/uc-dataviz/course-notes/raw/main/images/hexsticker.svg",
  # title_slide_background_size = "contain",
  # title_slide_background_position = "top",
  header_h1_font_size = "2rem",
  header_h2_font_size = "1.75rem",
  header_h3_font_size = "1.5rem",
  extra_css = list(
    "h1" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h2" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h3" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    ".tiny" = list("font-size" = "70%"),
    ".small" = list("font-size" = "90%"),
    ".midi" = list("font-size" = "150%"),
    ".tiny .remark-code" = list("font-size" = "70%"),
    ".small .remark-code" = list("font-size" = "90%"),
    ".midi .remark-code" = list("font-size" = "150%"),
    ".large" = list("font-size" = "200%"),
    ".xlarge" = list("font-size" = "600%"),
    ".huge" = list(
      "font-size" = "400%",
      "font-family" = "'Montserrat', sans-serif",
      "font-weight" = "bold"
    ),
    ".hand" = list(
      "font-family" = "'Gochi Hand', cursive",
      "font-size" = "125%"
    ),
    ".task" = list(
      "padding-right" = "10px",
      "padding-left" = "10px",
      "padding-top" = "3px",
      "padding-bottom" = "3px",
      "margin-bottom" = "6px",
      "margin-top" = "6px",
      "border-left" = "solid 5px #F1DE67",
      "background-color" = "#F3D03E"
    ),
    ".pull-left" = list(
      "width" = "49%",
      "float" = "left"
    ),
    ".pull-right" = list(
      "width" = "49%",
      "float" = "right"
    ),
    ".pull-left-wide" = list(
      "width" = "70%",
      "float" = "left"
    ),
    ".pull-right-narrow" = list(
      "width" = "27%",
      "float" = "right"
    ),
    ".pull-left-narrow" = list(
      "width" = "27%",
      "float" = "left"
    ),
    ".pull-right-wide" = list(
      "width" = "70%",
      "float" = "right"
    ),
    ".blue" = list(color = "#2A9BB7"),
    ".purple" = list(color = "#a493ba"),
    ".yellow" = list(color = "#f1de67"),
    ".gray" = list(color = "#222222")
  )
)

source(here::here("R", "slide-opts.R"))
```

```{r}
#| label = "pkgs",
#| include = FALSE,
#| cache = FALSE
library(tidyverse)
library(broom)
library(jsonlite)
library(stringr)
library(XML)
library(curl)
library(repurrrsive)
library(listviewer)
library(wordcloud)
library(tidytext)
library(manifestoR)
library(httr)
library(rtweet)
library(viridis)
library(flipbookr)

set.seed(1234)
theme_set(theme_minimal(base_size = 16))
```

class: inverse, middle

# Methods for obtaining data online

---

## Methods for obtaining data online

* Click and download
* Install and play
* API query
* Scraping

---

## Click and download

* `read.csv` or `readr::read_csv`
* `downloader` package or `curl`

---

## Application programming interface (API)

- Representational State Transfer (REST)
- Uniform Resource Location (URL)
- HTTP methods
    - GET
    - POST

---

## Application programming interface (API)

```{r}
#| label = "wikipedia",
#| echo = FALSE
knitr::include_graphics(path = "/img/wikipedia.png", error = FALSE)
```

---

## RESTful queries

1. Submit request to server via URL
1. Return result in a structured format
1. Parse results into a local format

---

## Install and play packages

* Packages with R functions written for existing APIs
* Useful because
    * Reproducible
    * Up-to-date (ideally)
    * Ease of access

---

class: inverse, middle

# Using APIs with existing R packages

---

## `manifestoR`

* Collects and organizes political party manifestos from around the world
* Over 1000 parties from 1945 until today in over 50 countries on five continents
* [`manifestoR`](https://github.com/ManifestoProject/manifestoR)

---

## API authentication

* Key/token
* Obtain key
* Store in `.Rprofile`

```{r}
#| label = "rprofile",
#| eval = FALSE
# in .Rprofile
options(this_is_my_key = "XXXX")

# later, in the R script:
key <- getOption("this_is_my_key")
```

--

* `usethis::edit_r_profile()`
* Read the documentation - different packages have different storage methods

---

## Load library and set API key

```{r}
#| label = "manifestor-load",
#| cache = FALSE
library(manifestoR)

# retrieve API key stored in .Rprofile
mp_setapikey(key = getOption("manifesto_key"))
```

---

## Retrieve the database

```{r}
#| label = "manifestor-db"
(mpds <- mp_maindataset())
```

---

```{r}
#| label = "manifesto-dist",
#| echo = FALSE
mpds %>%
  filter(countryname == "Sweden") %>%
  count(partyname) %>%
  ggplot(aes(fct_reorder(partyname, n), n)) +
  geom_col() +
  labs(
    title = "Political manifestos published in Sweden",
    x = NULL,
    y = "Total (1948-present)"
  ) +
  coord_flip() +
  theme_minimal(base_size = 14)
```

---

## Download manifestos

```{r}
#| label = "manifestor-corpus",
#| include = FALSE
# download documents
docs <- mp_corpus(countryname == "United States" & edate > as.Date("2016-01-01"))
```

```{r}
#| label = "manifestor-corpus-wordcloud",
#| dependson = "manifestor-corpus",
#| echo = FALSE
# generate wordcloud of most common terms
docs %>%
  tidy() %>%
  mutate(party = factor(party,
    levels = c(61320, 61620),
    labels = c("Democratic Party", "Republican Party")
  )) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  count(party, word, sort = TRUE) %>%
  drop_na() %>%
  reshape2::acast(word ~ party, value.var = "n", fill = 0) %>%
  comparison.cloud(max.words = 200)
```

---

## Census data with `tidycensus`

* API to access data from US Census Bureau
    * Decennial census
    * American Community Survey
* Returns tidy data frames with (optional) `sf` geometry
* Search for variables with `load_variables()`

---

## Store API key

```{r}
#| label = "tidycensus"
library(tidycensus)
```

```r
census_api_key("YOUR API KEY GOES HERE")
```

---

## Obtain data

```{r}
#| label = "income-usa"
usa_inc <- get_acs(
  geography = "state",
  variables = c(medincome = "B19013_001"),
  year = 2020
)
usa_inc
```

---

## Visualize data

```{r}
#| label = "income-usa-plot",
#| echo = FALSE,
#| fig.asp = 0.7,
#| out.width = "70%"
usa_inc %>%
  ggplot(aes(x = reorder(NAME, estimate), y = estimate)) +
  geom_pointrange(aes(
    ymin = estimate - moe,
    ymax = estimate + moe
  ),
  size = .25
  ) +
  scale_y_continuous(labels = scales::dollar) +
  coord_flip() +
  labs(
    title = "Household income by state",
    subtitle = "2020 American Community Survey (five-year estimates)",
    x = "",
    y = "ACS estimate (bars represent margin of error)"
  ) +
  theme_minimal(base_size = 11)
```

---

# Twitter API

* REST API
* Streaming API


--

* [`rtweet`](https://docs.ropensci.org/rtweet/)

---

# Using `rtweet`

```{r}
#| label = "twitter"
library(rtweet)
```

* Requires a Twitter account
* Prompt to authorize application on first usage

---


# Searching tweets

```{r}
#| label = "twitter-rstats"
rt <- search_tweets(
  q = "#rstats",
  n = 3000,
  include_rts = FALSE
)
rt
```

---

# Searching users

```{r}
#| label = "twitter-count"
countvoncount <- get_timeline(user = "countvoncount", n = 4000)
countvoncount
```

---

# Visualizing tweets

```{r}
#| label = "rstats-freq"
ts_plot(countvoncount, by = "1 week")
```

---

# Visualizing tweets


```{r}
#| label = "rstats-freq-day"
ts_plot(countvoncount, by = "1 month")
```

---

# Visualizing tweets

```{r}
#| label = "rstats-freq-clean",
#| fig.height = 3.5
ts_plot(countvoncount, by = "1 week") +
  theme(plot.title = element_text(face = "bold")) +
  labs(
    x = NULL, y = NULL,
    title = "Frequency of @countvoncount Twitter posts",
    subtitle = "Twitter status (tweet) counts aggregated using one week intervals",
    caption = "\nSource: Data collected from Twitter's REST API via rtweet"
  )
```

---

# Exercise: Practice using `rtweet`

.pull-left[

```{r}
#| echo = FALSE
include_graphics(path = "https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Katy_Perry%E2%80%93Zenith_Paris.jpg/360px-Katy_Perry%E2%80%93Zenith_Paris.jpg")
```

]

.pull-right[

```{r}
#| echo = FALSE
include_graphics(path = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Kim_Kardashian_West_2014.jpg/320px-Kim_Kardashian_West_2014.jpg")
```

]

---

class: inverse, middle

# Writing an API function

---

## Writing an API function

* No package for API
* Write your own function!
* [Open Movie Database](http://www.omdbapi.com/)

---

class: center, middle

<iframe width="840" height="473" src="https://www.youtube.com/embed/9LmAEVdPhl4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---

## Expected elements

1. Authentication Key/Token
1. Base URL
1. Search Parameters
1. Response Format

---

## Determine the shape of an API request

[Use the documentation](https://www.omdbapi.com/#examples)

--

```http
http://www.omdbapi.com/?apikey=[apikey]&t=Sharknado&y=2013
```

```{r}
#| echo = FALSE
GET(url = "http://www.omdbapi.com/?",
    query = list(t = "Sharknado",
                 y = 2013,
                 apikey = getOption("omdb_key"))
) %>%
  content(type = "text") %>%
  # print the contents in a clear structure
  prettify()
```

---

## `httr::GET()`

```{r}
#| label = "sharknado",
#| dependson = "omdb-key"
sharknado <- GET(url = "http://www.omdbapi.com/?",
    query = list(t = "Sharknado",
                 y = 2013,
                 apikey = getOption("omdb_key"))
)
```

---

## JavaScript Object Notation (JSON)

```{r}
#| label = "httr-json",
#| dependson = "sharknado",
#| echo = FALSE
content(sharknado, type = "text") %>%
  # print the contents in a clear structure
  prettify()
```

---

## JSON

```{r}
#| label = "sharknado-content",
#| dependson = "sharknado"
sharknado_df <- content(sharknado) %>%
  as_tibble()
sharknado_df
```

---

## Additional information from `GET()`

```{r}
#| label = "sharknado-url",
#| dependson = "sharknado",
#| eval = FALSE
sharknado$url
```

```{r}
#| label = "sharknado-url-hidden",
#| dependson = "sharknado",
#| echo = FALSE
str_replace(string = sharknado$url, pattern = getOption("omdb_key"), replacement = "[apikey]")
```

--

```{r}
#| label = "sharknado-status",
#| dependson = "sharknado"
status_code(sharknado)
```

---

## HTTP status code

Code | Status
-------|--------|
1xx    | Informational
2xx    | Success
3xx    | Redirection
4xx    | Client error (you did something wrong)
5xx    | Server error (server did something wrong)

> [A more intuitive guide](https://www.flickr.com/photos/girliemac/sets/72157628409467125)

---

## Iteration through a set of movies

```{r}
#| label = "omdb-function"
omdb_api <- function(title, api_key){
  # send GET request
  response <- GET(url = "http://www.omdbapi.com/?",
    query = list(t = title,
                 apikey = api_key)
  )
  
  # parse response to JSON
  response_df <- content(response) %>%
    as_tibble()
  
  # print a message to track progress
  message(glue::glue("Scraping {title}..."))
  
  return(response_df)
}
```

---

## Iteration through a set of movies

```{r}
#| label = "sharknados"
sharknados <- c("Sharknado", "Sharknado 2", "Sharknado 3",
                "Sharknado 4", "Sharknado 5")
```

```{r}
#| label = "iterate-movies",
#| dependson = c("omdb-function", "sharknados"),
#| message = TRUE
# modify function to delay by one second
omdb_api_slow <- purrr::slowly(f = omdb_api, rate = rate_delay(1))

# iterate over all the films
sharknados_df <- map_dfr(.x = sharknados, .f = omdb_api_slow, api_key = getOption("omdb_key"))
```

---

## Iteration through a set of movies

```{r}
#| label = "iterate-results",
#| dependson = "iterate-movies"
sharknados_df
```

---

## Messy API responses

```{r}
#| label = "omdb-recursive",
#| error = TRUE,
#| warning = FALSE
content(sharknado) %>%
  as_tibble()
```

---

## Whoops

```{r}
#| label = "omdb-str",
#| echo = FALSE
content(sharknado) %>%
  str()
```

---

class: inverse, middle

# Rectangling messy data

---

## Rectangling and `tidyr`

.task[
Art and craft of taking a deeply nested list and taming it into a tidy data set of rows and columns
]

--

* `unnest_longer()` - each row contains multiple observations
* `unnest_wider()` - each row contains a single observation
* `unnest_auto()` - make an educated guess
* `hoist()` - extract a specific element
  
---

## `unnest_wider()` and `hoist()`

```{r}
#| label = "gh-users"
str(gh_users, list.len = 3)
```

---

## `unnest_wider()` and `hoist()`

```{r}
#| label = "gh-users-df"
(users <- tibble(user = gh_users))
```

--

```{r}
#| label = "gh-users-names",
#| dependson = "gh-users-df"
names(users$user[[1]])
```

---

## `unnest_wider()`

```{r}
#| label = "gh-users-unnest-wider",
#| dependson = "gh-users-df"
users %>%
  unnest_wider(col = user)
```

---

## `hoist()`

```{r}
#| label = "gh-users-hoist",
#| dependson = "gh-users-df"
users %>%
  hoist(
    .col = user,
    followers = "followers",
    login = "login",
    url = "html_url"
  )
```

---

## `gh_repos` and nested list structures

```{r}
#| label = "gh-repos"
(repos <- tibble(repo = gh_repos))
```

---

## `unnest_longer()`

```{r}
#| label = "gh-repos-unnest-longer",
#| dependson = "gh-repos"
repos <- repos %>%
  unnest_longer(col = repo)
repos
```

---

## `unnest_longer()`

```{r}
#| label = "gh-repos-hoist",
#| dependson = "gh-repos-unnest-longer"
repos %>%
  hoist(
    .col = repo,
    login = c("owner", "login"),
    name = "name",
    homepage = "homepage",
    watchers = "watchers_count"
  )
```

---

```{r}
#| label = "gh-repos-auto",
#| include = FALSE
tibble(repo = gh_repos) %>%
  unnest_auto(col = repo) %>%
  unnest_auto(col = repo)
```

`r chunk_reveal(chunk_name = "gh-repos-auto")`

---

## ASOIAF characters

```{r}
#| label = "got"
chars <- tibble(char = got_chars)
chars
```

---

## ASOIAF characters

```{r}
#| label = "got-wider"
chars2 <- chars %>%
  unnest_wider(col = char)
chars2
```

---

## Nested list objects

```{r}
#| label = "got-list-cols",
#| dependson = "got-wider"
chars2 %>%
  select(where(is.list))
```

---

## Choose your own adventure

```{r}
#| echo = FALSE,
#| out.width = "30%"
include_graphics(path = "https://images-na.ssl-images-amazon.com/images/I/81E88dflPeL.jpg")
```

---

class: inverse, middle

# Every appearance per book/season

---

```{r}
#| label = "got-appearances",
#| dependson = "got-wider",
#| include = FALSE
select(
  .data = chars2,
  name, books, tvSeries
) %>%
  pivot_longer(
    cols = c(books, tvSeries),
    names_to = "media",
    values_to = "value"
  ) %>%
  unnest_longer(col = value)
```

`r chunk_reveal(chunk_name = "got-appearances", break_type = "auto", title = "## Every appearance per book/season")`

---

class: inverse, middle

# Match character's title to their name

---

```{r}
#| label = "got-title-name",
#| dependson = "got-wider",
#| include = FALSE
select(
  .data = chars2,
  name,
  title = titles
) %>%
  unnest_longer(col = title)
```

`r chunk_reveal(chunk_name = "got-title-name", break_type = "auto", title = "## Match character's title to their name")`

---

# May the force be with you

```{r}
#| echo = FALSE
include_graphics(path = "https://media.giphy.com/media/C0ZArORmrDQCRTIFnQ/giphy.gif")
```

