<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tune better models</title>
    <meta charset="utf-8" />
    <meta name="author" content="INFO 5940   Cornell University" />
    <script src="index_files/header-attrs/header-attrs.js"></script>
    <link href="index_files/panelset/panelset.css" rel="stylesheet" />
    <script src="index_files/panelset/panelset.js"></script>
    <link href="index_files/countdown/countdown.css" rel="stylesheet" />
    <script src="index_files/countdown/countdown.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Tune better models
]
.author[
### INFO 5940 <br /> Cornell University
]

---






class: inverse, middle

# Decision trees

---

# Decision Trees

To predict the outcome of a new data point:

- Uses rules learned from splits
- Each split maximizes information gain

---

&lt;img src="https://media.giphy.com/media/gj4ZruUQUnpug/source.gif" width="50%" style="display: block; margin: auto;" /&gt;

---



&lt;img src="index_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-6-1.png" width="80%" style="display: block; margin: auto;" /&gt;


---
class: middle, center

# Quiz

How do assess predictions here?

--

RMSE

---

&lt;img src="index_files/figure-html/rt-test-resid-1.png" width="80%" style="display: block; margin: auto;" /&gt;


---
class: middle, center
&lt;img src="https://raw.githubusercontent.com/EmilHvitfeldt/blog/master/static/blog/2019-08-09-authorship-classification-with-tidymodels-and-textrecipes_files/figure-html/unnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;" /&gt;

https://www.hvitfeldt.me/blog/authorship-classification-with-tidymodels-and-textrecipes/

---
class: middle, center
&lt;img src="https://www.kaylinpavlik.com/content/images/2019/12/dt-1.png" width="50%" style="display: block; margin: auto;" /&gt;

https://www.kaylinpavlik.com/classifying-songs-genres/

---
class: middle, center

&lt;img src="https://a3.typepad.com/6a0105360ba1c6970c01b7c95c61fb970b-pi" width="40%" style="display: block; margin: auto;" /&gt;

.footnote[[tweetbotornot2](https://github.com/mkearney/tweetbotornot2)]


---


&lt;img src="http://www.atarimania.com/8bit/screens/guess_the_animal.gif" width="80%" style="display: block; margin: auto;" /&gt;


---
class: middle, center

# What makes a good guesser?

--

High information gain per question (can it fly?)

--

Clear features (feathers vs. is it "small"?)

--

Order matters


---

&lt;img src="images/aus-standard-animals.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[[Australian Computing Academy](https://aca.edu.au/resources/decision-trees-classifying-animals/)]

---

&lt;img src="images/aus-standard-tree.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[[Australian Computing Academy](https://aca.edu.au/resources/decision-trees-classifying-animals/)]

---

&lt;img src="images/annotated-tree/annotated-tree.001.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/annotated-tree/annotated-tree.002.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/annotated-tree/annotated-tree.003.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/annotated-tree/annotated-tree.004.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/annotated-tree/annotated-tree.005.png" width="90%" style="display: block; margin: auto;" /&gt;

---

# To specify a model with `parsnip`

.right-column[

1\. Pick a .display[model] + .display[engine]

2\. Set the .display[mode] (if needed)

]

---

# To specify a decision tree model with `parsnip`



```r
tree_mod &lt;-
  decision_tree(engine = "rpart") %&gt;%
  set_mode("classification")
```

---
class: middle, center

&lt;img src="index_files/figure-html/alz-tree-01-1.png" width="40%" style="display: block; margin: auto;" /&gt;


```
##  nn    Class  Imp Con                                              cover
##   4 Impaired [.85 .15] when tau &gt;=        5.9 &amp; VEGF &lt;  17           18%
##  10 Impaired [.78 .22] when tau &gt;=        6.8 &amp; VEGF &gt;=       17      3%
##  44 Impaired [.67 .33] when tau is 6.3 to 6.8 &amp; VEGF is 17 to 18      3%
##   3  Control [.11 .89] when tau &lt;  5.9                               57%
##  45  Control [.09 .91] when tau is 5.9 to 6.3 &amp; VEGF is 17 to 18      4%
##  23  Control [.07 .93] when tau is 5.9 to 6.8 &amp; VEGF &gt;=       18     15%
```

---

.pull-left[

&lt;img src="index_files/figure-html/unnamed-chunk-19-1.png" width="80%" style="display: block; margin: auto;" /&gt;

]

.pull-right[
&lt;img src="index_files/figure-html/unnamed-chunk-20-1.png" width="80%" style="display: block; margin: auto;" /&gt;
]

---

class: inverse

# ‚è± Your turn 1

Here is our very-vanilla parsnip model specification for a decision tree (also in your qmd)...


```r
tree_mod &lt;-
  decision_tree(engine = "rpart") %&gt;%
  set_mode("classification")
```

And a workflow:

```r
tree_wf &lt;-
  workflow() %&gt;%
  add_formula(Class ~ .) %&gt;%
  add_model(tree_mod)
```


For decision trees, no recipe really required üéâ

---

class: inverse

# ‚è± Your turn 1

Fill in the blanks to return the accuracy and ROC AUC for this model using 10-fold cross-validation.

<div class="countdown" id="timer_6346f941" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">02</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---


```r
set.seed(100)
tree_wf %&gt;%
  fit_resamples(resamples = alz_folds) %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 6
##   .metric  .estimator  mean     n std_err .config           
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
## 1 accuracy binary     0.792    10  0.0361 Preprocessor1_Mod‚Ä¶
## 2 roc_auc  binary     0.744    10  0.0320 Preprocessor1_Mod‚Ä¶
```



---

# `args()`

Print the arguments for a **parsnip** model specification.


```r
args(decision_tree)
```

---

# `decision_tree()`

Specifies a decision tree model


```r
decision_tree(engine = "rpart", tree_depth = 30, min_n = 20, cost_complexity = .01)
```

--

*either* mode works!

---

# `decision_tree()`

Specifies a decision tree model


```r
decision_tree(
  engine = "rpart", # default computational engine
  tree_depth = 30, # max tree depth
  min_n = 20, # smallest node allowed
  cost_complexity = .01 # 0 &gt; cp &gt; 0.1
)
```

---

# `set_args()`

Change the arguments for a **parsnip** model specification.

```r
_mod %&gt;% set_args(tree_depth = 3)
```

---


```r
decision_tree(engine = "rpart") %&gt;%
  set_mode("classification") %&gt;%
* set_args(tree_depth = 3)
## Decision Tree Model Specification (classification)
## 
## Main Arguments:
##   tree_depth = 3
## 
## Computational engine: rpart
```

---


```r
*decision_tree(engine = "rpart", tree_depth = 3) %&gt;%
  set_mode("classification")
## Decision Tree Model Specification (classification)
## 
## Main Arguments:
##   tree_depth = 3
## 
## Computational engine: rpart
```

---

# `tree_depth`

Cap the maximum tree depth.

A method to stop the tree early. Used to prevent overfitting.


```r
tree_mod %&gt;% set_args(tree_depth = 30)
```

---



&lt;img src="index_files/figure-html/unnamed-chunk-31-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-32-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

# `min_n`

Set minimum `n` to split at any node.

Another early stopping method. Used to prevent overfitting.


```r
tree_mod %&gt;% set_args(min_n = 20)
```

---

# Quiz

What value of `min_n` would lead to the *most overfit* tree?

--

`min_n` = 1

---
class: middle, center, frame

# Recap: early stopping

| `parsnip` arg | `rpart` arg | default | overfit? |
|---------------|-------------|:-------:|:--------:|
| `tree_depth`  | `maxdepth`  |    30   |‚¨ÜÔ∏è|
| `min_n`       | `minsplit`  |    20   |‚¨áÔ∏è|


---

# `cost_complexity`

Adds a cost or penalty to error rates of more complex trees.

A way to prune a tree. Used to prevent overfitting.


```r
tree_mod %&gt;% set_args(cost_complexity = .01)
```

--

Closer to zero ‚û°Ô∏è larger trees. 

Higher penalty ‚û°Ô∏è smaller trees. 

---

&lt;img src="index_files/figure-html/unnamed-chunk-35-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-36-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-37-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---
name: bonsai
background-image: url(images/kari-shea-AVqh83jStMA-unsplash.jpg)
background-position: left
background-size: contain
class: middle

---
template: bonsai

.pull-right[

# Consider the bonsai

1. Small pot

1. Strong shears

]

---
template: bonsai

.pull-right[

# Consider the bonsai

1. ~~Small pot~~ .display[Early stopping]

1. ~~Strong shears~~ .display[Pruning]

]

---
class: middle, center, frame

# Recap: early stopping &amp; pruning

| `parsnip` arg | `rpart` arg | default | overfit? |
|---------------|-------------|:-------:|:--------:|
| `tree_depth`  | `maxdepth`  |    30   |‚¨ÜÔ∏è|
| `min_n`       | `minsplit`  |    20   |‚¨áÔ∏è|
| `cost_complexity`  | `cp`  |    .01  |‚¨áÔ∏è|

---
class: middle, center

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; engine &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; parsnip &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; original &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; rpart &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; tree_depth &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; maxdepth &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; rpart &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; min_n &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; minsplit &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; rpart &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cost_complexity &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cp &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;https://rdrr.io/cran/rpart/man/rpart.control.html&gt;


---

&lt;img src="index_files/figure-html/unnamed-chunk-39-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-40-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-41-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-42-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-43-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-44-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/unnamed-chunk-45-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---
class: middle, frame

# Axiom

There is an inverse relationship between  
model .display[accuracy] and model .display[interpretability].

---

class: inverse, middle

# Random forests

---

# `rand_forest()`

Specifies a random forest model



```r
rand_forest(mtry = 4, trees = 500, min_n = 1)
```

--

*either* mode works!

---

# `rand_forest()`

Specifies a random forest model


```r
rand_forest(
  engine = "ranger", # default computational engine
  mtry = 4, # predictors seen at each node
  trees = 500, # trees per forest
  min_n = 1 # smallest node allowed
)
```

---

class: inverse

# ‚è± Your turn 2

Create a new parsnip model called `rf_mod`, which will learn an ensemble of classification trees from our training data using the **ranger** engine. Update your `tree_wf` with this new model.

Fit your workflow with 10-fold cross-validation and compare the ROC AUC of the random forest to your single decision tree model --- which predicts the test set better?

*Hint: you'll need https://www.tidymodels.org/find/parsnip/*

<div class="countdown" id="timer_6346f9bf" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">04</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---


```r
rf_mod &lt;-
  rand_forest(engine = "ranger") %&gt;%
  set_mode("classification")

rf_wf &lt;-
  tree_wf %&gt;%
  update_model(rf_mod)

set.seed(100)
rf_wf %&gt;%
  fit_resamples(resamples = alz_folds) %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 6
##   .metric  .estimator  mean     n std_err .config           
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
## 1 accuracy binary     0.833    10  0.0139 Preprocessor1_Mod‚Ä¶
## 2 roc_auc  binary     0.894    10  0.0186 Preprocessor1_Mod‚Ä¶
```

---

# `mtry` 

The number of predictors that will be randomly sampled at each split when creating the tree models.


```r
rand_forest(mtry = 11)
```

**ranger** default = `floor(sqrt(num_predictors))`

---

.pull-left[

### Single decision tree

```r
tree_mod &lt;- decision_tree(engine = "rpart") %&gt;%
  set_mode("classification")

tree_wf &lt;- workflow() %&gt;%
  add_formula(Class ~ .) %&gt;%
  add_model(tree_mod)

set.seed(100)
tree_res &lt;- tree_wf %&gt;%
  fit_resamples(
    resamples = alz_folds,
    control = control_resamples(save_pred = TRUE)
  )

tree_res %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 6
##   .metric  .estimator  mean     n std_err .config           
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
## 1 accuracy binary     0.792    10  0.0361 Preprocessor1_Mod‚Ä¶
## 2 roc_auc  binary     0.744    10  0.0320 Preprocessor1_Mod‚Ä¶
```
]

--

.pull-right[


### A random forest of trees

```r
rf_mod &lt;- rand_forest(engine = "ranger") %&gt;%
  set_mode("classification")

rf_wf &lt;- tree_wf %&gt;%
  update_model(rf_mod)

set.seed(100)
rf_res &lt;- rf_wf %&gt;%
  fit_resamples(
    resamples = alz_folds,
    control = control_resamples(save_pred = TRUE)
  )

rf_res %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 6
##   .metric  .estimator  mean     n std_err .config           
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
## 1 accuracy binary     0.833    10  0.0139 Preprocessor1_Mod‚Ä¶
## 2 roc_auc  binary     0.894    10  0.0186 Preprocessor1_Mod‚Ä¶
```
]

---


.pull-left[

### Single decision tree
&lt;img src="index_files/figure-html/unnamed-chunk-53-1.png" width="80%" style="display: block; margin: auto;" /&gt;
]

--

.pull-right[


### A random forest of trees
&lt;img src="index_files/figure-html/unnamed-chunk-54-1.png" width="80%" style="display: block; margin: auto;" /&gt;
]

---

class: inverse

# ‚è± Your turn 3

Challenge: Fit 3 more random forest models, each using 3, 8, and 30 variables at each split. Update your `rf_wf` with each new model. Which value maximizes the area under the ROC curve?

<div class="countdown" id="timer_6346f6fe" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">03</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---


```r
rf3_mod &lt;- rf_mod %&gt;%
* set_args(mtry = 3)

rf8_mod &lt;- rf_mod %&gt;%
* set_args(mtry = 8)

rf30_mod &lt;- rf_mod %&gt;%
* set_args(mtry = 30)
```

---


```r
rf3_wf &lt;- rf_wf %&gt;%
  update_model(rf3_mod)

set.seed(100)
rf3_wf %&gt;%
  fit_resamples(resamples = alz_folds) %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 6
##   .metric  .estimator  mean     n std_err .config           
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
## 1 accuracy binary     0.786    10  0.0183 Preprocessor1_Mod‚Ä¶
## 2 roc_auc  binary     0.861    10  0.0209 Preprocessor1_Mod‚Ä¶
```

---

```r
rf8_wf &lt;- rf_wf %&gt;%
  update_model(rf8_mod)

set.seed(100)
rf8_wf %&gt;%
  fit_resamples(resamples = alz_folds) %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 6
##   .metric  .estimator  mean     n std_err .config           
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
## 1 accuracy binary     0.816    10  0.0177 Preprocessor1_Mod‚Ä¶
## 2 roc_auc  binary     0.889    10  0.0183 Preprocessor1_Mod‚Ä¶
```

---

```r
rf30_wf &lt;- rf_wf %&gt;%
  update_model(rf30_mod)

set.seed(100)
rf30_wf %&gt;%
  fit_resamples(resamples = alz_folds) %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 6
##   .metric  .estimator  mean     n std_err .config           
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
## 1 accuracy binary     0.829    10  0.0108 Preprocessor1_Mod‚Ä¶
## 2 roc_auc  binary     0.898    10  0.0196 Preprocessor1_Mod‚Ä¶
```


---

class: inverse, middle

# üé∑ Fitting and tuning models with `tune`

---

class: middle, center, frame

# `tune` 

Functions for fitting and tuning models

&lt;https://tune.tidymodels.org&gt;

&lt;iframe src="https://tune.tidymodels.org" width="100%" height="400px" data-external="1"&gt;&lt;/iframe&gt;

---

# `tune()`

A placeholder for hyper-parameters to be "tuned"


```r
nearest_neighbor(neighbors = tune())
```


---

# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[


```r
tune_grid(
  object,
  resamples,
  ...,
  grid = 10,
  metrics = NULL,
  control = control_grid()
)
```

]

---

# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[


```r
tune_grid(
* object,
  resamples,
  ...,
  grid = 10,
  metrics = NULL,
  control = control_grid()
)
```

]

--

.pull-right[
One of:

+ A parsnip `model` object

+ A `workflow`

]

---

# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[


```r
tune_grid(
* object,
* preprocessor,
  resamples,
  ...,
  grid = 10,
  metrics = NULL,
  control = control_grid()
)
```

]

.pull-right[
A `model` + `recipe`
]

---

# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[


```r
tune_grid(
  object,
  resamples,
  ...,
* grid = 10,
  metrics = NULL,
  control = control_grid()
)
```

]

.pull-right[
One of:

+ A positive integer. 

+ A data frame of tuning combinations.

]

---

# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[


```r
tune_grid(
  object,
  resamples,
  ...,
* grid = 10,
  metrics = NULL,
  control = control_grid()
)
```

]

.pull-right[
Number of candidate parameter sets to be created automatically; `10` is the default.
]

---

class: inverse

# ‚è± Your Turn 4

Here's our random forest model plus workflow to work with.


```r
rf_mod &lt;- rand_forest(engine = "ranger") %&gt;%
  set_mode("classification")

rf_wf &lt;- workflow() %&gt;%
  add_formula(Class ~ .) %&gt;%
  add_model(rf_mod)
```

---
class: inverse

# ‚è± Your Turn 4

Here is the output from `fit_resamples()`...


```r
set.seed(100) # Important!
rf_results &lt;- rf_wf %&gt;%
  fit_resamples(resamples = alz_folds)

rf_results %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 6
##   .metric  .estimator  mean     n std_err .config           
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
## 1 accuracy binary     0.833    10  0.0139 Preprocessor1_Mod‚Ä¶
## 2 roc_auc  binary     0.894    10  0.0186 Preprocessor1_Mod‚Ä¶
```


---
class: inverse

# ‚è± Your Turn 4

Edit the random forest model to tune the `mtry` and `min_n` hyperparameters. 

Update your workflow to use the tuned model.

Then use `tune_grid()` to find the best combination of hyper-parameters to maximize `roc_auc`; let tune set up the grid for you.

How does it compare to the average ROC AUC across folds from `fit_resamples()`?

<div class="countdown" id="timer_6346f9bd" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---


```r
rf_tuner &lt;- rand_forest(
    engine = "ranger",
    mtry = tune(),
    min_n = tune()
  ) %&gt;%
  set_mode("classification")

rf_wf &lt;- rf_wf %&gt;%
  update_model(rf_tuner)

set.seed(100) # Important!
rf_results &lt;- rf_wf %&gt;%
  tune_grid(resamples = alz_folds)
```

---


```r
rf_results %&gt;%
  collect_metrics()
## # A tibble: 20 √ó 8
##     mtry min_n .metric  .estim‚Ä¶¬π  mean     n std_err .config
##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
##  1    53    28 accuracy binary   0.843    10 0.00946 Prepro‚Ä¶
##  2    53    28 roc_auc  binary   0.894    10 0.0212  Prepro‚Ä¶
##  3    37    36 accuracy binary   0.843    10 0.0102  Prepro‚Ä¶
##  4    37    36 roc_auc  binary   0.891    10 0.0188  Prepro‚Ä¶
##  5    74    21 accuracy binary   0.849    10 0.0111  Prepro‚Ä¶
##  6    74    21 roc_auc  binary   0.892    10 0.0216  Prepro‚Ä¶
##  7    10    13 accuracy binary   0.816    10 0.0128  Prepro‚Ä¶
##  8    10    13 roc_auc  binary   0.886    10 0.0182  Prepro‚Ä¶
##  9    80     8 accuracy binary   0.839    10 0.0176  Prepro‚Ä¶
## 10    80     8 roc_auc  binary   0.899    10 0.0217  Prepro‚Ä¶
## # ‚Ä¶ with 10 more rows, and abbreviated variable name
## #   ¬π‚Äã.estimator
```

---

```r
rf_results %&gt;%
  collect_metrics(summarize = FALSE)
## # A tibble: 200 √ó 7
##    id      mtry min_n .metric  .estimator .estimate .config 
##    &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;   
##  1 Fold01    53    28 accuracy binary         0.806 Preproc‚Ä¶
##  2 Fold01    53    28 roc_auc  binary         0.879 Preproc‚Ä¶
##  3 Fold02    53    28 accuracy binary         0.833 Preproc‚Ä¶
##  4 Fold02    53    28 roc_auc  binary         0.898 Preproc‚Ä¶
##  5 Fold03    53    28 accuracy binary         0.8   Preproc‚Ä¶
##  6 Fold03    53    28 roc_auc  binary         0.824 Preproc‚Ä¶
##  7 Fold04    53    28 accuracy binary         0.867 Preproc‚Ä¶
##  8 Fold04    53    28 roc_auc  binary         0.972 Preproc‚Ä¶
##  9 Fold05    53    28 accuracy binary         0.833 Preproc‚Ä¶
## 10 Fold05    53    28 roc_auc  binary         0.807 Preproc‚Ä¶
## # ‚Ä¶ with 190 more rows
```


---

# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[


```r
tune_grid(
  object,
  resamples,
  ...,
* grid = df,
  metrics = NULL,
  control = control_grid()
)
```

]

.pull-right[
A data frame of tuning combinations.
]

---

# `expand_grid()`

Takes one or more vectors, and returns a data frame holding all combinations of their values.


```r
expand_grid(mtry = c(1, 5), min_n = 1:3)
## # A tibble: 6 √ó 2
##    mtry min_n
##   &lt;dbl&gt; &lt;int&gt;
## 1     1     1
## 2     1     2
## 3     1     3
## 4     5     1
## 5     5     2
## 6     5     3
```

--

.footnote[tidyr package; see also base `expand.grid()`]


---

# `show_best()`

Shows the .display[n] most optimum combinations of hyper-parameters


```r
rf_results %&gt;%
  show_best(metric = "roc_auc", n = 5)
```

---


```
## # A tibble: 5 √ó 8
##    mtry min_n .metric .estimator  mean     n std_err .config
##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
## 1    80     8 roc_auc binary     0.899    10  0.0217 Prepro‚Ä¶
## 2   113     5 roc_auc binary     0.897    10  0.0222 Prepro‚Ä¶
## 3    43    20 roc_auc binary     0.896    10  0.0192 Prepro‚Ä¶
## 4    53    28 roc_auc binary     0.894    10  0.0212 Prepro‚Ä¶
## 5   100    31 roc_auc binary     0.893    10  0.0223 Prepro‚Ä¶
```

---

# `autoplot()`

Quickly visualize tuning results


```r
rf_results %&gt;% autoplot()
```

---

&lt;img src="index_files/figure-html/unnamed-chunk-75-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

# `select_best()`

Shows the .display[top] combination of hyper-parameters.


```r
alz_best &lt;- rf_results %&gt;%
  select_best(metric = "roc_auc")

alz_best
```

---


```
## # A tibble: 1 √ó 3
##    mtry min_n .config              
##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;                
## 1    80     8 Preprocessor1_Model05
```

---

# `finalize_workflow()`

Replaces `tune()` placeholders in a model/recipe/workflow with a set of hyper-parameter values.


```r
last_rf_workflow &lt;- rf_wf %&gt;%
  finalize_workflow(alz_best)
```

---
background-image: url(images/diamonds.jpg)
background-size: contain
background-position: left
class: middle, center
background-color: #f5f5f5

.pull-right[
## We are ready to touch the jewels...

## The .display[testing set]!

]


---

# `last_fit()`



```r
last_rf_fit &lt;- last_rf_workflow %&gt;%
  last_fit(split = alz_split)
```

---


```r
last_rf_fit
## # Resampling results
## # Manual resampling 
## # A tibble: 1 √ó 6
##   splits           id             .metrics .notes   .predi‚Ä¶¬π
##   &lt;list&gt;           &lt;chr&gt;          &lt;list&gt;   &lt;list&gt;   &lt;list&gt;  
## 1 &lt;split [298/35]&gt; train/test sp‚Ä¶ &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;
## # ‚Ä¶ with 1 more variable: .workflow &lt;list&gt;, and abbreviated
## #   variable name ¬π‚Äã.predictions
```

---

class: inverse

# ‚è± Your Turn 5

Use `select_best()`, `finalize_workflow()`, and `last_fit()` to take the best combination of hyper-parameters from `rf_results` and use them to predict the test set.

How does our actual test ROC AUC compare to our cross-validated estimate?

<div class="countdown" id="timer_6346f984" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---


```r
alz_best &lt;- rf_results %&gt;%
  select_best(metric = "roc_auc")

last_rf_workflow &lt;- rf_wf %&gt;%
  finalize_workflow(alz_best)

last_rf_fit &lt;- last_rf_workflow %&gt;%
  last_fit(split = alz_split)

last_rf_fit %&gt;%
  collect_metrics()
```

---

# Final metrics


```r
last_rf_fit %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 4
##   .metric  .estimator .estimate .config             
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary         0.857 Preprocessor1_Model1
## 2 roc_auc  binary         0.9   Preprocessor1_Model1
```

---

# Final test predictions


```r
last_rf_fit %&gt;%
  collect_predictions()
## # A tibble: 35 √ó 7
##    id            .pred‚Ä¶¬π .pred‚Ä¶¬≤  .row .pred‚Ä¶¬≥ Class .config
##    &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;   &lt;fct&gt; &lt;chr&gt;  
##  1 train/test s‚Ä¶  0.0226   0.977     7 Control Cont‚Ä¶ Prepro‚Ä¶
##  2 train/test s‚Ä¶  0.201    0.799    14 Control Cont‚Ä¶ Prepro‚Ä¶
##  3 train/test s‚Ä¶  0.618    0.382    16 Impair‚Ä¶ Impa‚Ä¶ Prepro‚Ä¶
##  4 train/test s‚Ä¶  0.626    0.374    27 Impair‚Ä¶ Impa‚Ä¶ Prepro‚Ä¶
##  5 train/test s‚Ä¶  0.692    0.308    28 Impair‚Ä¶ Impa‚Ä¶ Prepro‚Ä¶
##  6 train/test s‚Ä¶  0.174    0.826    32 Control Impa‚Ä¶ Prepro‚Ä¶
##  7 train/test s‚Ä¶  0.0117   0.988    54 Control Cont‚Ä¶ Prepro‚Ä¶
##  8 train/test s‚Ä¶  0.188    0.812    58 Control Cont‚Ä¶ Prepro‚Ä¶
##  9 train/test s‚Ä¶  0.0851   0.915    60 Control Cont‚Ä¶ Prepro‚Ä¶
## 10 train/test s‚Ä¶  0.456    0.544    90 Control Cont‚Ä¶ Prepro‚Ä¶
## # ‚Ä¶ with 25 more rows, and abbreviated variable names
## #   ¬π‚Äã.pred_Impaired, ¬≤‚Äã.pred_Control, ¬≥‚Äã.pred_class
```

---


```r
roc_values &lt;- last_rf_fit %&gt;%
  collect_predictions() %&gt;%
  roc_curve(truth = Class, estimate = .pred_Impaired)
autoplot(roc_values)
```

&lt;img src="index_files/figure-html/unnamed-chunk-84-1.png" width="70%" style="display: block; margin: auto;" /&gt;

---

# The set-up


```r
set.seed(100) # Important!

# holdout method
alz_split &lt;- initial_split(alz, strata = Class, prop = .9)
alz_train &lt;- training(alz_split)
alz_test &lt;- testing(alz_split)

# add cross-validation
set.seed(100)
alz_folds &lt;- vfold_cv(alz_train, v = 10, strata = Class)
```

---

# The tune-up


```r
# here comes the actual ML bits‚Ä¶

# pick model to tune
rf_tuner &lt;- rand_forest(
  engine = "ranger",
  mtry = tune(),
  min_n = tune()
) %&gt;%
  set_mode("classification")

rf_wf &lt;- workflow() %&gt;%
  add_formula(Class ~ .) %&gt;%
  add_model(rf_tuner)

rf_results &lt;- rf_wf %&gt;%
  tune_grid(
    resamples = alz_folds,
    control = control_grid(save_pred = TRUE)
  )
```

---

# Quick check-in...


```r
rf_results %&gt;%
  collect_predictions() %&gt;%
  group_by(.config, mtry, min_n) %&gt;%
  summarize(folds = n_distinct(id))
## # A tibble: 10 √ó 4
## # Groups:   .config, mtry [10]
##    .config                mtry min_n folds
##    &lt;chr&gt;                 &lt;int&gt; &lt;int&gt; &lt;int&gt;
##  1 Preprocessor1_Model01   121    29    10
##  2 Preprocessor1_Model02    37     7    10
##  3 Preprocessor1_Model03    87    38    10
##  4 Preprocessor1_Model04    61    15    10
##  5 Preprocessor1_Model05     4     6    10
##  6 Preprocessor1_Model06    24    24    10
##  7 Preprocessor1_Model07   111    11    10
##  8 Preprocessor1_Model08    40    28    10
##  9 Preprocessor1_Model09    68    33    10
## 10 Preprocessor1_Model10    91    19    10
```

---

# The match up!

.pull-left[

```r
show_best(rf_results, metric = "roc_auc", n = 5)
## # A tibble: 5 √ó 8
##    mtry min_n .metric .estimator  mean     n std_err .config
##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
## 1    37     7 roc_auc binary     0.897    10  0.0201 Prepro‚Ä¶
## 2    24    24 roc_auc binary     0.897    10  0.0173 Prepro‚Ä¶
## 3    61    15 roc_auc binary     0.895    10  0.0197 Prepro‚Ä¶
## 4    91    19 roc_auc binary     0.893    10  0.0207 Prepro‚Ä¶
## 5    87    38 roc_auc binary     0.893    10  0.0223 Prepro‚Ä¶

# pick final model workflow
alz_best &lt;- rf_results %&gt;%
  select_best(metric = "roc_auc")

alz_best
## # A tibble: 1 √ó 3
##    mtry min_n .config              
##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;                
## 1    37     7 Preprocessor1_Model02
```
]

.pull-right[
&lt;img src="index_files/figure-html/unnamed-chunk-89-1.png" width="80%" style="display: block; margin: auto;" /&gt;

]

---

# The wrap-up

.pull-left[

```r
last_rf_workflow &lt;- rf_wf %&gt;%
  finalize_workflow(alz_best)

last_rf_workflow
## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Formula
## Model: rand_forest()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## Class ~ .
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = 37
##   min_n = 7
## 
## Computational engine: ranger
```
]

--

.pull-right[

```r
# train + test final model
last_rf_fit &lt;- last_rf_workflow %&gt;%
  last_fit(split = alz_split)

# explore final model
last_rf_fit %&gt;%
  collect_metrics()
## # A tibble: 2 √ó 4
##   .metric  .estimator .estimate .config             
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary         0.857 Preprocessor1_Model1
## 2 roc_auc  binary         0.876 Preprocessor1_Model1

last_rf_fit %&gt;%
  collect_predictions() %&gt;%
  roc_curve(truth = Class, estimate = .pred_Impaired) %&gt;%
  autoplot()
```
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
