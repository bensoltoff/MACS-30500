---
title: "Text analysis: classification and topic modeling"
author: "INFO 5940 <br /> Cornell University"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      highlightStyle: magula
      highlightLines: true
      highlightLanguage: r
      ratio: 16:9
      countIncrementalSlides: false
---

```{r}
#| label = "setup",
#| include = FALSE
# generate CSS file
library(xaringanthemer)
style_duo_accent(
  primary_color = "#B31B1B",
  secondary_color = "#F8981D",
  inverse_header_color = "#222222",
  black_color = "#222222",
  header_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  text_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  code_font_google = xaringanthemer::google_font("Source Code Pro"),
  base_font_size = "24px",
  code_font_size = "20px",
  # title_slide_background_image = "https://github.com/uc-dataviz/course-notes/raw/main/images/hexsticker.svg",
  # title_slide_background_size = "contain",
  # title_slide_background_position = "top",
  header_h1_font_size = "2rem",
  header_h2_font_size = "1.75rem",
  header_h3_font_size = "1.5rem",
  extra_css = list(
    "h1" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h2" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h3" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    ".tiny" = list("font-size" = "70%"),
    ".small" = list("font-size" = "90%"),
    ".midi" = list("font-size" = "150%"),
    ".tiny .remark-code" = list("font-size" = "70%"),
    ".small .remark-code" = list("font-size" = "90%"),
    ".midi .remark-code" = list("font-size" = "150%"),
    ".large" = list("font-size" = "200%"),
    ".xlarge" = list("font-size" = "600%"),
    ".huge" = list(
      "font-size" = "400%",
      "font-family" = "'Montserrat', sans-serif",
      "font-weight" = "bold"
    ),
    ".hand" = list(
      "font-family" = "'Gochi Hand', cursive",
      "font-size" = "125%"
    ),
    ".task" = list(
      "padding-right" = "10px",
      "padding-left" = "10px",
      "padding-top" = "3px",
      "padding-bottom" = "3px",
      "margin-bottom" = "6px",
      "margin-top" = "6px",
      "border-left" = "solid 5px #F1DE67",
      "background-color" = "#F3D03E"
    ),
    ".pull-left" = list(
      "width" = "49%",
      "float" = "left"
    ),
    ".pull-right" = list(
      "width" = "49%",
      "float" = "right"
    ),
    ".pull-left-wide" = list(
      "width" = "70%",
      "float" = "left"
    ),
    ".pull-right-narrow" = list(
      "width" = "27%",
      "float" = "right"
    ),
    ".pull-left-narrow" = list(
      "width" = "27%",
      "float" = "left"
    ),
    ".pull-right-wide" = list(
      "width" = "70%",
      "float" = "right"
    ),
    ".blue" = list(color = "#2A9BB7"),
    ".purple" = list(color = "#a493ba"),
    ".yellow" = list(color = "#f1de67"),
    ".gray" = list(color = "#222222")
  )
)

source(here::here("R", "slide-opts.R"))
xaringanExtra::use_panelset()
```

```{r}
#| label = "pkgs",
#| include = FALSE,
#| cache = FALSE
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  collapse = TRUE
)

library(tidyverse)
library(tidymodels)
library(tidytext)
library(themis)
library(rjson)
library(topicmodels)
library(here)
library(patchwork)
library(tictoc)
library(countdown)
library(colorspace)

set.seed(1234)
theme_set(theme_minimal(base_size = 16))
```

class: inverse, middle

# Supervised text classification

---

## Supervised learning

1. Hand-code a small set of documents $N = `r scales::comma(1e03)`$
1. Train a statistical learning model on the hand-coded data
1. Evaluate the effectiveness of the statistical learning model
1. Apply the final model to the remaining set of documents $N = `r scales::comma(1e06)`$

---

## `USCongress`

```{r}
#| label = "get-docs",
#| echo = FALSE
# get USCongress data
data(USCongress, package = "rcis")

# topic labels
major_topics <- tibble(
  major = c(1:10, 12:21, 99),
  label = c(
    "Macroeconomics", "Civil rights, minority issues, civil liberties",
    "Health", "Agriculture", "Labor and employment", "Education", "Environment",
    "Energy", "Immigration", "Transportation", "Law, crime, family issues",
    "Social welfare", "Community development and housing issues",
    "Banking, finance, and domestic commerce", "Defense",
    "Space, technology, and communications", "Foreign trade",
    "International affairs and foreign aid", "Government operations",
    "Public lands and water management", "Other, miscellaneous"
  )
) %>%
  mutate(label = factor(major, levels = major, labels = label))

congress <- as_tibble(USCongress) %>%
  mutate(text = as.character(text)) %>%
  left_join(major_topics)
glimpse(congress)
```

```{r}
#| label = "docs-example",
#| dependson = "get-docs",
#| echo = FALSE
head(congress$text)
```

---

## Split the data set

```{r}
#| label = "split",
#| dependson = "get-docs"
set.seed(123)

# convert response variable to factor
congress <- congress %>%
  mutate(major = factor(x = major, levels = major, labels = label))

# split into training and testing sets
congress_split <- initial_split(data = congress, strata = major, prop = .8)
congress_split

congress_train <- training(congress_split)
congress_test <- testing(congress_split)

# generate cross-validation folds
congress_folds <- vfold_cv(data = congress_train, strata = major)
```

---

## Class imbalance

```{r}
#| label = "major-topic-dist",
#| dependson = "get-docs",
#| echo = FALSE
ggplot(data = congress, mapping = aes(x = fct_infreq(major) %>% fct_rev())) +
  geom_bar() +
  coord_flip() +
  labs(
    title = "Distribution of legislation",
    subtitle = "By major policy topic",
    x = NULL,
    y = "Number of bills"
  )
```

---

## Preprocessing the data frame

```{r}
#| label = "recipe",
#| dependson = "split"
congress_rec <- recipe(major ~ text, data = congress_train)
```

```{r}
#| label = "recipe-steps",
#| dependson = "recipe"
library(textrecipes)

congress_rec <- congress_rec %>%
  step_tokenize(text) %>%
  step_stopwords(text) %>%
  step_tokenfilter(text, max_tokens = 500) %>%
  step_tfidf(text) %>%
  step_downsample(major)
```

---

## Define the model

```{r}
#| label = "tree-spec"
tree_spec <- decision_tree() %>%
  set_mode("classification") %>%
  set_engine("C5.0")

tree_spec
```

---

## Train the model

```{r}
#| label = "tree-wf",
#| dependson = c("recipe-steps", "tree-spec")
tree_wf <- workflow() %>%
  add_recipe(congress_rec) %>%
  add_model(tree_spec)
```

```{r}
#| label = "tree-fit",
#| dependson = "tree-wf"
set.seed(123)

tree_cv <- fit_resamples(
  tree_wf,
  congress_folds,
  control = control_resamples(save_pred = TRUE)
)
```

```{r}
#| label = "tree-metrics",
#| dependson = "tree-fit"
tree_cv_metrics <- collect_metrics(tree_cv)
tree_cv_predictions <- collect_predictions(tree_cv)
tree_cv_metrics
```

---

## Confusion matrix

```{r}
#| label = "tree-confusion",
#| dependson = "tree-metrics",
#| echo = FALSE
conf_mat_resampled(x = tree_cv, tidy = FALSE) %>%
  autoplot(type = "heatmap") +
  scale_y_discrete(labels = function(x) str_wrap(x, 20)) +
  scale_x_discrete(labels = function(x) str_wrap(x, 20))
```

---

# Name That Tune!

.pull-left[

```{r}
#| echo: false
include_graphics(path = "https://media.giphy.com/media/10JbbHzFsBpg40/giphy.gif")
```

]

.pull-right[

```{r}
#| echo: false
include_graphics(path = "https://media.giphy.com/media/7SKWbnycqb2Pze62Zk/giphy.gif")
```

]

```{r}
#| label = "countdown",
#| cache = FALSE,
#| echo = FALSE
countdown(minutes = 15)
```

---

class: inverse, middle

# Topic modeling

---

## Topic modeling

* Themes
* Probabilistic topic models
* Latent Dirichlet allocation

---

## Topic and topic

1. I ate a banana and spinach smoothie for breakfast.
1. I like to eat broccoli and bananas.
1. Chinchillas and kittens are cute.
1. My sister adopted a kitten yesterday.
1. Look at this cute hamster munching on a piece of broccoli.

---

## LDA document structure

* Decide on the number of words N the document will have
    * [Dirichlet probability distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution)
    * Fixed set of $k$ topics
* Generate each word in the document:
    * Pick a topic
    * Generate the word
* LDA backtracks from this assumption

---

## `appa`

```{r}
#| echo = FALSE,
#| out.width = "65%"
knitr::include_graphics(path = "/img/appa-avatar.gif", error = FALSE)
```

---

## `appa`

```r
remotes::install_github("averyrobbins1/appa")
```

```{r}
#| label = "appa"
library(appa)
data("appa")

glimpse(appa)
```

---

## Create the recipe

```{r}
#| label = "appa-recipe",
#| dependson = "appa"
appa_rec <- recipe(~ id + character_words, data = appa) %>%
  step_tokenize(character_words) %>%
  step_stopwords(character_words, stopword_source = "smart") %>%
  step_ngram(character_words, num_tokens = 5, min_num_tokens = 1) %>%
  step_tokenfilter(character_words, max_tokens = 5000) %>%
  step_tf(character_words)
```

---

## Bake the recipe

```{r}
#| label = "appa-bake",
#| dependson = "appa-recipe"
appa_prep <- prep(appa_rec)

appa_df <- bake(appa_prep, new_data = NULL)
appa_df %>%
  slice(1:5)
```

---

## Convert to document-term matrix

.tiny[
```{r}
#| label = "appa-dtm",
#| dependson = "appa-bake"
appa_dtm_prep <- appa_df %>%
  # convert to long format
  pivot_longer(
    cols = -id,
    names_to = "token",
    values_to = "n"
  ) %>%
  # remove tokens with 0
  filter(n != 0) %>%
  # clean the token column so it just includes the token
  mutate(
    token = str_remove(string = token, pattern = "tf_character_words_")
  )

# id must be consecutive with no gaps
appa_new_id <- appa_dtm_prep %>%
  distinct(id) %>%
  mutate(new_id = row_number())

# create document-term matrix
appa_dtm <- left_join(x = appa_dtm_prep, y = appa_new_id) %>%
  cast_dtm(document = new_id, term = token, value = n)
appa_dtm
```
]

---

## $k=4$

```{r}
#| label = "appa-topic-4",
#| dependson = "appa-dtm"
appa_lda4 <- LDA(appa_dtm, k = 4, control = list(seed = 123))
```

```{r}
#| label = "appa-4-topn",
#| dependson = "appa-topic-4",
#| echo = FALSE,
#| out.width = "70%"
appa_lda4_td <- tidy(appa_lda4)

top_terms <- appa_lda4_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(
    topic = factor(topic),
    term = reorder_within(term, beta, topic)
  ) %>%
  ggplot(aes(term, beta, fill = topic)) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  scale_x_reordered() +
  scale_fill_discrete_qualitative() +
  facet_wrap(facets = vars(topic), scales = "free", ncol = 2) +
  coord_flip()
```
---

## $k=12$

```{r}
#| label = "appa-topic-12",
#| dependson = "appa-dtm",
#| echo = FALSE
appa_lda12 <- LDA(appa_dtm, k = 12, control = list(seed = 123))
```

```{r}
#| label = "appa-12-topn",
#| dependson = "appa-topic-12",
#| echo = FALSE
appa_lda12_td <- tidy(appa_lda12)

top_terms <- appa_lda12_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(
    topic = factor(topic),
    term = reorder_within(term, beta, topic)
  ) %>%
  ggplot(aes(term, beta, fill = topic)) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  scale_x_reordered() +
  scale_fill_discrete_qualitative() +
  facet_wrap(facets = vars(topic), scales = "free", ncol = 3) +
  coord_flip() +
  theme_minimal(base_size = 10)
```

---

## Perplexity

* A statistical measure of how well a probability model predicts a sample
* Given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents
* Perplexity for LDA model with 12 topics
    * `r perplexity(appa_lda12)`

---

## Perplexity

```{r}
#| label = "appa-lda-compare",
#| dependson = "appa-dtm",
#| echo = FALSE
n_topics <- c(2, 4, 10, 20, 50, 100)

# cache the models and only estimate if they don't already exist
if (file.exists(here("static", "extras", "appa-lda-compare.Rdata"))) {
  load(file = here("static", "extras", "appa-lda-compare.Rdata"))
} else {
  library(furrr)
  plan(multiprocess)

  tic()
  appa_lda_compare <- n_topics %>%
    future_map(LDA, x = appa_dtm, control = list(seed = 123), .progress = TRUE)
  toc()
  save(appa_dtm, appa_lda_compare, file = here("static", "extras", "appa-lda-compare.Rdata"))
}
```

```{r} 
#| label = "appa_lda_compare_viz",
#| dependson = "appa_lda_compare",
#| echo = FALSE
tibble(
  k = n_topics,
  perplex = map_dbl(appa_lda_compare, perplexity)
) %>%
  ggplot(aes(k, perplex)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Evaluating LDA topic models",
    subtitle = "Optimal number of topics (smaller is better)",
    x = "Number of topics",
    y = "Perplexity"
  )
```

---

## $k=100$

```{r}
#| label = "appa-100-topn",
#| dependson = "appa-lda-compare",
#| echo = FALSE
appa_lda_td <- tidy(appa_lda_compare[[6]])

top_terms <- appa_lda_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  filter(topic <= 12) %>%
  mutate(
    topic = factor(topic),
    term = reorder_within(term, beta, topic)
  ) %>%
  ggplot(aes(term, beta, fill = topic)) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  scale_x_reordered() +
  scale_fill_discrete_qualitative() +
  facet_wrap(facets = vars(topic), scales = "free", ncol = 3) +
  coord_flip() +
  theme_minimal(base_size = 10)
```

---

## LDAvis

* Interactive visualization of LDA model results
1. What is the meaning of each topic?
1. How prevalent is each topic?
1. How do the topics relate to each other?
